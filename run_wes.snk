#### USAGE
#### 1) First load snakemake
#### module load NiaEnv/2018a
#### module load python/3.6.4-anaconda5.1.0
#### source activate snakemake
#### snakemake -s AN_WGS_script/run_wes.snk --cores 1 -j 50 --cluster "sbatch -N 1 -t 1:00:00 --ntasks 80
#### --output=logs/%x_%j.log" --config input=tcga_wxs_sample_list_fastq.tsv
#### outdir=$SCRATCH/AN_WGS/20220606_tcga_wxs exome_bed=$SCRATCH/AN_WGS/AN_WGS_script/WES_bedfiles/whole_exome_agilent_1.1_refseq_plus_3_boosters.targetIntervals_GRCh38_liftover.bed --ri
import pandas as pd
import os
import time

# initial settings

#TMP = "$SCRATCH/temp"

localrules: all, symlink_reffiles, generate_intervals, make_loci_files_for_ascat, tabix_bedfile

###
### LOAD SAMPLES
###

configfile: "AN_WGS_script/niagara_config.yaml"

print("\n***INPUT FILE: " + config['input'] + "***\n")
INPUT = pd.read_csv(config['input'],names = ['Patient','Sex','n_vs_t','Sample','Lane','Fastq1','Fastq2'],header=0)
INPUT['Lane'] = INPUT.Lane.apply(str)
INPUT['Sample_Lane'] = INPUT.Sample + "_" + INPUT.Lane
SAMPLE =  INPUT['Sample'].unique()
PAT = INPUT.Patient.drop_duplicates()
TUMOR = INPUT[(INPUT.n_vs_t == 1)].Sample.drop_duplicates()
SAMPLE_LANE = INPUT.Sample_Lane
print(INPUT)

### PRINT OUTPUT DIRECTORY
OUTDIR = config['outdir']
print("***OUTPUT DIRECTORY: " + OUTDIR + "***")
EXOME_BED = config['EXOME_BED']

###
### GET SAMPLES TO USE MULTI-TUMOUR VARIANT CALLING
###
Multi = INPUT[(INPUT.n_vs_t == 1)]
Multi = Multi[['Patient','Sample']].drop_duplicates()
Multi.loc[:,'Combined'] = ""
Multi.loc[:,"num_tumours"] = 1
for x in Multi['Patient'].drop_duplicates():
	COMBINED_mutect_samples = ""
	print(x)
	n = 1
	for y in Multi[Multi.Patient == x].Sample.drop_duplicates():
		print(y)
		COMBINED_mutect_samples = y + "_" + COMBINED_mutect_samples
		Multi.loc[(Multi.Patient == x),'num_tumours'] = n
		n = n + 1
	COMBINED_mutect_samples = COMBINED_mutect_samples[:-1]
	Multi.loc[(Multi.Patient == x),'Combined']= COMBINED_mutect_samples

Multi['path'] = OUTDIR + "/results/mutect2_multi/"  + Multi.Combined + "_vs_" + Multi.Patient + "-N/" \
+ Multi.Combined + "_vs_" + Multi.Patient + "-N_snpEff.ann.vcf.gz"
if config['run_phylowgs'] == "True":
	Multi['phylowgs_path'] = OUTDIR + "/results/phyloWGS/" + Multi.Combined + "_vs_" + Multi.Patient + "-N/trees.zip"
	Multi['phylowgs_tree_json_path'] = OUTDIR + "/results/phyloWGS/" + Multi.Combined + "_vs_" + Multi.Patient + "-N/tree_likelihoods.txt"
	phylowgs_output_list = 	Multi.phylowgs_path.drop_duplicates().tolist(),
	phylowgs_tree_output_list = Multi.phylowgs_tree_json_path.drop_duplicates().tolist()
else:
	phylowgs_output_list = None
	phylowgs_tree_output_list = None
##
print(phylowgs_output_list)
print(phylowgs_tree_output_list)
Multi = Multi[Multi.num_tumours > 1]


###
###	REFERENCE FILES
###
REF_fasta = config["reference"]["directory"] + config["reference"]["fasta"]
REF_dbsnp = config["reference"]["directory"] + config["reference"]["dbsnp"]
REF_known_indels = config["reference"]["directory"] + config["reference"]["known_indels"]
REF_gnomAD = config["reference"]["directory"] + config["reference"]["gnomAD"]
REF_pon = config["reference"]["directory"] + config["reference"]["pon"]
REF_exac_common = config["reference"]["directory"] + config["reference"]["exac_common"]
### Some settings for TITAN
CLUST = {1:[1], 2:[1,2], 3:[1,2,3], 4:[1,2,3,4], 5:[1,2,3,4,5], 6:[1,2,3,4,5,6], 7:[1,2,3,4,5,6,7], 8:[1,2,3,4,5,6,7,8], 9:[1,2,3,4,5,6,7,8,9], 10:[1,2,3,4,5,6,7,8,9,10]}
PLOIDY = {2:[2], 3:[2,3], 4:[2,3,4]}
CHRS = ['chr1','chr2','chr3','chr4','chr5','chr6','chr7','chr8','chr9','chr10','chr11','chr12','chr13','chr14','chr15','chr16','chr17','chr18','chr19','chr20','chr21','chr22','chrX']


###get titan FILES
titan_output_files = []
for tumor in TUMOR:
	tumor_titan_output = expand(OUTDIR + "/results/titan/hmm/titanCNA_ploidy{ploidy}/{tumor}_vs_{patient}-N_cluster{clustNum}.titan.txt",patient = tumor.rsplit('-',1)[0],tumor = tumor,clustNum=CLUST[config["titan"]["TitanCNA_maxNumClonalClusters"]],ploidy=PLOIDY[config["titan"]["TitanCNA_maxPloidy"]])
	titan_output_files.extend(tumor_titan_output)
	tumor_titan_output = expand(OUTDIR + "/results/titan/hmm/titanCNA_ploidy{ploidy}/{tumor}_vs_{patient}-N_cluster{clustNum}.params.txt",patient = tumor.rsplit('-',1)[0],tumor = tumor,clustNum=CLUST[config["titan"]["TitanCNA_maxNumClonalClusters"]],ploidy=PLOIDY[config["titan"]["TitanCNA_maxPloidy"]])
	titan_output_files.extend(tumor_titan_output)
	tumor_titan_output = expand(OUTDIR + "/results/titan/hmm/titanCNA_ploidy{ploidy}/{tumor}_vs_{patient}-N_cluster{clustNum}.segs.txt",patient = tumor.rsplit('-',1)[0],tumor = tumor,clustNum=CLUST[config["titan"]["TitanCNA_maxNumClonalClusters"]],ploidy=PLOIDY[config["titan"]["TitanCNA_maxPloidy"]])
	titan_output_files.extend(tumor_titan_output)
	tumor_titan_output = expand(OUTDIR + "/results/titan/hmm/titanCNA_ploidy{ploidy}/{tumor}_vs_{patient}-N_cluster{clustNum}.seg",patient = tumor.rsplit('-',1)[0],tumor = tumor,clustNum=CLUST[config["titan"]["TitanCNA_maxNumClonalClusters"]],ploidy=PLOIDY[config["titan"]["TitanCNA_maxPloidy"]])
	titan_output_files.extend(tumor_titan_output)
	tumor_titan_output = expand(OUTDIR + "/results/titan/hmm/titanCNA_ploidy{ploidy}/{tumor}_vs_{patient}-N_cluster{clustNum}.seg",patient = tumor.rsplit('-',1)[0],tumor = tumor,clustNum=CLUST[config["titan"]["TitanCNA_maxNumClonalClusters"]],ploidy=PLOIDY[config["titan"]["TitanCNA_maxPloidy"]])
	titan_output_files.extend(tumor_titan_output)
	tumor_titan_output = expand(OUTDIR + "/results/titan/hmm/{tumor}_vs_{patient}-N_optimalClusterSolution.txt",patient = tumor.rsplit('-',1)[0],tumor = tumor)
	titan_output_files.extend(tumor_titan_output)
	tumor_titan_output = expand(OUTDIR+ "/results/titan/hmm/optimalClusterSolution/{tumor}_vs_{patient}-N/",patient = tumor.rsplit('-',1)[0],tumor = tumor)
	titan_output_files.extend(tumor_titan_output)

###
### Final Results
###
rule all:
	input:
		###FASTQC + BWA Alignment
		expand(OUTDIR + "/QC/fastqc/{sample_lane}/fastqc_complete", sample_lane = SAMPLE_LANE),
		expand(OUTDIR + "/Recal/{sample}.recal.bam", sample = SAMPLE),
		### using zip https://endrebak.gitbooks.io/the-snakemake-book/chapters/expand/expand.html
		###BAMQC + samtools_stats
		expand(OUTDIR + "/QC/samtools_stats/{sample}/{sample}.samtools.stats.out",sample = SAMPLE),
		expand(OUTDIR + "/QC/bamqc/{sample}/qualimapReport.html",sample = SAMPLE),
		####
		####VARIANT CALLING OUTPUTS
		####
		expand(OUTDIR + "/results/mutect2/{tumor}_vs_{patient}-N/{tumor}_vs_{patient}-N_snpEff.ann.vcf.gz",zip, patient = [x.rsplit('-',1)[0] for x in TUMOR],tumor = TUMOR),
		expand(OUTDIR + "/results/mutect2/{tumor}_vs_{patient}-N/{tumor}_vs_{patient}-N_snpEff.ann.passOnly.vcf.gz",zip, patient = [x.rsplit('-',1)[0] for x in TUMOR],tumor = TUMOR),
		Multi.path.drop_duplicates().tolist(),
		#### Manta
		expand(OUTDIR + "/results/Manta/{tumor}_vs_{patient}-N/Manta_snpeff_{tumor}_vs_{patient}-N.candidateSV.ann.vcf.gz",zip, patient = [x.rsplit('-',1)[0] for x in TUMOR],tumor = TUMOR),
		expand(OUTDIR + "/results/Manta/{tumor}_vs_{patient}-N/Manta_snpeff_{tumor}_vs_{patient}-N.candidateSmallIndels.ann.vcf.gz",zip, patient = [x.rsplit('-',1)[0] for x in TUMOR],tumor = TUMOR),
		expand(OUTDIR + "/results/Manta/{tumor}_vs_{patient}-N/Manta_snpeff_{tumor}_vs_{patient}-N.diploidSV.ann.vcf.gz",zip, patient = [x.rsplit('-',1)[0] for x in TUMOR],tumor = TUMOR),
		expand(OUTDIR + "/results/Manta/{tumor}_vs_{patient}-N/Manta_snpeff_{tumor}_vs_{patient}-N.somaticSV.ann.vcf.gz",zip, patient = [x.rsplit('-',1)[0] for x in TUMOR],tumor = TUMOR),
		###TitanCNA
		expand(OUTDIR + "/filtered/{samples}.filtered.bam", samples=SAMPLE),
		expand(OUTDIR + "/results/titan/hetPosns/{tumor}/{tumor}.{chr}.vcf",tumor = TUMOR,chr=CHRS),
		expand(OUTDIR + "/results/titan/tumCounts/{tumor}/{tumor}.tumCounts.{chr}.txt",tumor = TUMOR,chr=CHRS),
		expand(OUTDIR + "/results/readDepth/{samples}.bin{binSize}.wig",samples=SAMPLE,binSize=str(config["titan"]["binSize"])),
		titan_output_files
	threads: 1
	container:
		config["singularity"]["multiqc"]
	params:
		time = time.strftime('%Y%m%d'),
		input_csv = config['input']
	shell:
		"""
		multiqc {OUTDIR} -n {OUTDIR}/pipeline_info/reports/multiqc_{params.time}.html
		cp {params.input_csv} {OUTDIR}/Sample_{params.time}.csv
		"""


###
### Step by step
###


### Symlink all reference files to make singularity easier
rule symlink_reffiles:
	input:
		config["reference"]["directory"] + config["reference"]["fasta"],
		config["reference"]["directory"] + config["reference"]["dbsnp"],
		config["reference"]["directory"] + config["reference"]["known_indels"],
		config["reference"]["directory"] + config["reference"]["gnomAD"],
		config["reference"]["directory"] + config["reference"]["pon"],
		config["reference"]["directory"] + config["reference"]["exac_common"],
		config["reference"]["directory"] + config["reference"]["ascat_acloci"],
		config["reference"]["directory"] + config["reference"]["ascat_acloci_gc"]
	output:
		OUTDIR + "/reference/" + config["reference"]["fasta"],
		OUTDIR + "/reference/" + config["reference"]["dbsnp"],
		OUTDIR + "/reference/" + config["reference"]["known_indels"],
		OUTDIR + "/reference/" + config["reference"]["gnomAD"],
		OUTDIR + "/reference/" + config["reference"]["pon"],
		OUTDIR + "/reference/" + config["reference"]["exac_common"],
		OUTDIR + "/reference/" + config["reference"]["ascat_acloci"],
		OUTDIR + "/reference/" + config["reference"]["ascat_acloci_gc"]
	threads: 1
	params:
		original_ref_dir = config["reference"]["directory"],
		target_ref_dir = OUTDIR + "/reference/"
	shell:
		"""
		ln -sf {params.original_ref_dir}* {params.target_ref_dir}
		"""

##SET NUMBERS FROM 0000 to 0099
NUMBERS = [str(a)+str(b)+str(c)+str(d) for a in range(0,1) for b in range(0,1) for c in range(0,1) for d in range(0,10)]

rule generate_intervals:
	input:
		ref_fasta = OUTDIR + "/reference/" + config["reference"]["fasta"],
		exome_bed = EXOME_BED
	output:
		expand(OUTDIR + "/pipeline_info/intervals/{num}-scattered.interval_list", num = NUMBERS)
	threads: 1
	resources:
		time = 60,
		mem_mb = 2500
	container:
		config["singularity"]["gatk"]
	shell:
		"""
		gatk --java-options "-Xmx2g" SplitIntervals \
		-R {input.ref_fasta} \
		-L {input.exome_bed} \
		--scatter-count 10 \
		-O {OUTDIR}/pipeline_info/intervals
		"""


###Align
include: "snakemake_scripts/wgs_align.snk"

###Markdup recal
include: "snakemake_scripts/wgs_markdup_recal.snk"

###Bam QC
include: "snakemake_scripts/wes_bam_qc.snk"

### Mutect2 individual
include: "snakemake_scripts/wgs_mutect2_individual.snk"

### Mutect2 co-variant calling mode
include: "snakemake_scripts/wgs_mutect2_together.snk"

### Manta
include: "snakemake_scripts/wes_manta.snk"

config["titan"]["ichorCNA_exons"] = EXOME_BED ### Set the exon file to the BED file for exons
### TitanCNA
include: "snakemake_scripts/titan_cna/wgs_titanCNA.snk"
